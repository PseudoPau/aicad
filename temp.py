"""
å›¾ç‰‡åˆ†æå™¨ - 

æ”¯æŒçš„æ–¹æ¡ˆï¼š
1. æ™ºè°± AI GLM-4Vï¼ˆæ¨èï¼Œåœ¨çº¿ APIï¼Œè¯†åˆ«èƒ½åŠ›å¼ºï¼‰
2. ç¡…åŸºæµåŠ¨ Qwen2-VLï¼ˆå¼€æºæ¨¡å‹ï¼Œä¾¿å®œï¼Œè®¡æ•°å‡†ç¡®ï¼‰
3. Ollama + LLaVAï¼ˆæœ¬åœ°è¿è¡Œï¼‰
4. Hugging Face Transformersï¼ˆBLIPï¼ŒåŸºç¡€åŠŸèƒ½ï¼‰
"""

import base64
import requests
import json
from pathlib import Path
import os


class ImageAnalyzer:
    """ä½¿ç”¨å¼€æºæ¨¡å‹åˆ†æå›¾ç‰‡å†…å®¹"""

    def __init__(self, method="zhipu", api_key=None):
        """
        åˆå§‹åŒ–å›¾ç‰‡åˆ†æå™¨

        Args:
            method: ä½¿ç”¨çš„æ–¹æ³•ï¼Œå¯é€‰:
                   - "zhipu": æ™ºè°± AI GLM-4Vï¼ˆæ¨èï¼Œè¯†åˆ«èƒ½åŠ›å¼ºï¼‰
                   - "siliconflow": ç¡…åŸºæµåŠ¨ Qwen2-VLï¼ˆå¼€æºï¼Œè®¡æ•°å¥½ï¼‰
                   - "ollama": Ollama æœ¬åœ°
                   - "huggingface": HF Transformers
            api_key: API å¯†é’¥ï¼ˆåœ¨çº¿æ–¹æ¡ˆéœ€è¦ï¼‰
        """
        self.method = method
        self.api_key = api_key or os.getenv(f"{method.upper()}_API_KEY")

    def analyze_with_zhipu(self, image_path, prompt="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"):
        """
        ä½¿ç”¨æ™ºè°± AI GLM-4V æ¨¡å‹åˆ†æå›¾ç‰‡ï¼ˆæ¨èï¼Œè¯†åˆ«èƒ½åŠ›å¼ºï¼‰

        å…è´¹æ³¨å†Œ: https://open.bigmodel.cn/
        æ¯æœˆæœ‰å…è´¹é¢åº¦ï¼Œè§†è§‰ç†è§£èƒ½åŠ›å¼ºï¼Œé€‚åˆè®¡æ•°å’Œç»†èŠ‚è¯†åˆ«

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not self.api_key:
            return """
é”™è¯¯: æœªè®¾ç½® API Key

è·å–æ­¥éª¤ï¼ˆ1åˆ†é’Ÿå®Œæˆï¼‰:
1. è®¿é—® https://open.bigmodel.cn/
2. æ³¨å†Œè´¦å·ï¼ˆæ‰‹æœºå·å³å¯ï¼‰
3. è¿›å…¥"API Keys"é¡µé¢åˆ›å»ºå¯†é’¥
4. æ¯æœˆæœ‰å…è´¹é¢åº¦ï¼Œé€‚åˆè´§æ¶è¯†åˆ«ä»»åŠ¡

ä½¿ç”¨æ–¹æ³•:
analyzer = ImageAnalyzer(method="zhipu", api_key="ä½ çš„å¯†é’¥")
"""

        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')

        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        payload = {
            "model": "glm-4v",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ]
        }

        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except requests.exceptions.HTTPError as e:
            if response.status_code == 401:
                return "é”™è¯¯: API Key æ— æ•ˆï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®"
            return f"HTTP é”™è¯¯: {e}\nå“åº”: {response.text}"
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze_with_siliconflow(self, image_path, prompt="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"):
        """
        ä½¿ç”¨ç¡…åŸºæµåŠ¨ Qwen2-VL æ¨¡å‹åˆ†æå›¾ç‰‡ï¼ˆå¼€æºæ¨¡å‹ï¼Œè®¡æ•°å‡†ç¡®ï¼‰

        æ³¨å†Œ: https://siliconflow.cn/
        ä»·æ ¼æä½ï¼Œä½¿ç”¨ Qwen2-VL å¼€æºæ¨¡å‹ï¼Œå¯¹ä¸­æ–‡å’Œè®¡æ•°æ”¯æŒå¥½

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not self.api_key:
            return """
é”™è¯¯: æœªè®¾ç½® API Key

è·å–æ­¥éª¤:
1. è®¿é—® https://siliconflow.cn/
2. æ³¨å†Œè´¦å·
3. è·å– API Key
4. ä»·æ ¼æä½ï¼Œé€‚åˆæ‰¹é‡å¤„ç†

ä½¿ç”¨æ–¹æ³•:
analyzer = ImageAnalyzer(method="siliconflow", api_key="ä½ çš„å¯†é’¥")
"""

        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')

        url = "https://api.siliconflow.cn/v1/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        payload = {
            "model": "Pro/Qwen/Qwen2-VL-7B-Instruct",  # Qwen2-VL å¯¹è®¡æ•°å’Œç»†èŠ‚è¯†åˆ«å¥½
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            "stream": False
        }

        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze_with_ollama(self, image_path, prompt="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"):
        """
        ä½¿ç”¨ Ollama + LLaVA æ¨¡å‹åˆ†æå›¾ç‰‡

        éœ€è¦å…ˆå®‰è£… Ollama:
        1. ä¸‹è½½: https://ollama.ai/download
        2. è¿è¡Œ: ollama pull llava

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')

        # è°ƒç”¨ Ollama API
        url = "http://localhost:11434/api/generate"
        payload = {
            "model": "llava",
            "prompt": prompt,
            "images": [image_data],
            "stream": False
        }

        try:
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            result = response.json()
            return result.get("response", "")

        except requests.exceptions.ConnectionError:
            return "é”™è¯¯: æ— æ³•è¿æ¥åˆ° Ollamaã€‚è¯·ç¡®ä¿å·²å®‰è£…å¹¶è¿è¡Œ Ollama æœåŠ¡ã€‚\nå®‰è£…æ­¥éª¤:\n1. è®¿é—® https://ollama.ai/download\n2. å®‰è£…åè¿è¡Œ: ollama pull llava"
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze_with_huggingface(self, image_path, prompt=None):
        """
        ä½¿ç”¨ Hugging Face Transformers çš„ BLIP-2 æ¨¡å‹åˆ†æå›¾ç‰‡

        éœ€è¦å®‰è£…: pip install transformers pillow torch

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯ï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆå®Œæ•´æè¿°ï¼‰

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        try:
            from transformers import BlipProcessor, BlipForConditionalGeneration
            from PIL import Image
            import torch

            print("æ­£åœ¨åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")

            # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
            processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
            model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large")

            # è¯»å–å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')

            print("æ­£åœ¨åˆ†æå›¾ç‰‡...")

            if prompt:
                # å¦‚æœæœ‰æç¤ºè¯ï¼Œä½¿ç”¨æ¡ä»¶ç”Ÿæˆï¼ˆVisual Question Answeringï¼‰
                inputs = processor(image, return_tensors="pt")
                # out = model.generate(**inputs, max_length=100, num_beams=5)
                out = model.generate(
                    **inputs,
                    max_length=100,           # å¢åŠ æœ€å¤§é•¿åº¦
                    # min_length=20,            # è®¾ç½®æœ€å°é•¿åº¦ï¼Œç¡®ä¿è¾“å‡ºå®Œæ•´
                    # num_beams=5,              # ä½¿ç”¨æŸæœç´¢ï¼Œæé«˜è´¨é‡
                    length_penalty=1.0,       # é•¿åº¦æƒ©ç½š
                    early_stopping=True,
                    temperature=1.0,
                    do_sample=True
                )
            else:
                # æ— æ¡ä»¶ç”Ÿæˆï¼ˆImage Captioningï¼‰- ç”Ÿæˆå®Œæ•´æè¿°
                inputs = processor(image, return_tensors="pt")
                out = model.generate(
                    **inputs,
                    max_length=100,           # å¢åŠ æœ€å¤§é•¿åº¦
                    # min_length=20,            # è®¾ç½®æœ€å°é•¿åº¦ï¼Œç¡®ä¿è¾“å‡ºå®Œæ•´
                    # num_beams=5,              # ä½¿ç”¨æŸæœç´¢ï¼Œæé«˜è´¨é‡
                    length_penalty=1.0,       # é•¿åº¦æƒ©ç½š
                    early_stopping=True,
                    temperature=1.0,
                    do_sample=True
                )

            description = processor.decode(out[0], skip_special_tokens=True)

            return description

        except ImportError:
            return "é”™è¯¯: ç¼ºå°‘å¿…è¦çš„åº“ã€‚è¯·è¿è¡Œ: pip install transformers pillow torch"
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze_with_qwen_vl(self, image_path, prompt="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"):
        """
        ä½¿ç”¨ Ollama + Qwen2-VL æ¨¡å‹åˆ†æå›¾ç‰‡ï¼ˆä¸­æ–‡æ•ˆæœæ›´å¥½ï¼‰

        éœ€è¦å…ˆè¿è¡Œ: ollama pull qwen2-vl

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')

        # è°ƒç”¨ Ollama API
        url = "http://localhost:11434/api/generate"
        payload = {
            "model": "qwen2-vl",
            "prompt": prompt,
            "images": [image_data],
            "stream": False
        }

        try:
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            result = response.json()
            return result.get("response", "")

        except requests.exceptions.ConnectionError:
            return "é”™è¯¯: æ— æ³•è¿æ¥åˆ° Ollamaã€‚è¯·è¿è¡Œ: ollama pull qwen2-vl"
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze(self, image_path, prompt=None):
        """
        åˆ†æå›¾ç‰‡å†…å®¹

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå¯é€‰ï¼‰
                   - å¯¹äºè´§æ¶è¯†åˆ«ï¼Œå»ºè®®è¯¦ç»†æè¿°éœ€æ±‚
                   - ä¾‹å¦‚ï¼š"è¯·ä»”ç»†è§‚å¯Ÿè¿™ä¸ªè´§æ¶ï¼Œå‘Šè¯‰æˆ‘ï¼š1. æœ‰å¤šå°‘å±‚ 2. æ¯å±‚çš„ç»“æ„"

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not Path(image_path).exists():
            return f"é”™è¯¯: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"

        # å¦‚æœæ²¡æœ‰æä¾› promptï¼Œä½¿ç”¨è´§æ¶è¯†åˆ«çš„é»˜è®¤æç¤ºè¯
        if prompt is None:
            prompt = """è¯·ä»”ç»†åˆ†æè¿™å¼ è´§æ¶å›¾ç‰‡ï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. è´§æ¶æœ‰å¤šå°‘å±‚ï¼Ÿï¼ˆè¯·æ•°æ¸…æ¥šæ°´å¹³çš„å±‚æ¿ï¼‰
2. æ¯å±‚çš„ç»“æ„å’Œç‰¹å¾
3. è´§æ¶çš„ç»„è£…æ–¹å¼å’Œéƒ¨ä»¶ï¼ˆå¦‚ç«‹æŸ±ã€å±‚æ¿ã€è¿æ¥ä»¶ç­‰ï¼‰
4. ä»»ä½•å¯è§çš„ç»†èŠ‚

è¯·ç»™å‡ºè¯¦ç»†ã€å‡†ç¡®çš„åˆ†æã€‚"""

        print(f"ä½¿ç”¨æ–¹æ³•: {self.method}")
        print(f"åˆ†æå›¾ç‰‡: {image_path}")
        print(f"æç¤ºè¯: {prompt}\n")

        if self.method == "zhipu":
            return self.analyze_with_zhipu(image_path, prompt)
        elif self.method == "siliconflow":
            return self.analyze_with_siliconflow(image_path, prompt)
        elif self.method == "ollama":
            return self.analyze_with_ollama(image_path, prompt)
        elif self.method == "qwen":
            return self.analyze_with_qwen_vl(image_path, prompt)
        elif self.method == "huggingface":
            return self.analyze_with_huggingface(image_path, prompt)
        else:
            return f"ä¸æ”¯æŒçš„æ–¹æ³•: {self.method}"


def main():
    """ä¸»å‡½æ•° - è´§æ¶è¯†åˆ«ç¤ºä¾‹"""

    # é…ç½®ä½ çš„è´§æ¶å›¾ç‰‡è·¯å¾„
    image_path = "./input_img/img_test_03.jpg"  # ä¿®æ”¹ä¸ºä½ çš„å›¾ç‰‡è·¯å¾„

    # ========== æ–¹æ¡ˆ1: æ™ºè°± AI GLM-4Vï¼ˆæ¨èï¼‰==========
    # è¯†åˆ«èƒ½åŠ›å¼ºï¼Œé€‚åˆè®¡æ•°å’Œç»†èŠ‚åˆ†æ
    # æ³¨å†Œ: https://open.bigmodel.cn/
    analyzer = ImageAnalyzer(
        method="zhipu", 
        api_key="c1a1c3a1ee394b4c88a2b138f2d01af6.GOiAiXgVVUsFbI7P"  # æ›¿æ¢ä¸ºä½ çš„å¯†é’¥
    )

    # ========== æ–¹æ¡ˆ2: ç¡…åŸºæµåŠ¨ Qwen2-VLï¼ˆå¼€æºæ¨¡å‹ï¼Œä¾¿å®œï¼‰==========
    # Qwen2-VL å¯¹è®¡æ•°å’Œä¸­æ–‡æ”¯æŒå¥½
    # æ³¨å†Œ: https://siliconflow.cn/
    # analyzer = ImageAnalyzer(
    #     method="siliconflow",
    #     api_key="ä½ çš„APIå¯†é’¥"
    # )

    # ========== æ–¹æ¡ˆ3: æœ¬åœ° Ollamaï¼ˆéœ€ä¸‹è½½ 4GBï¼‰==========
    # analyzer = ImageAnalyzer(method="ollama")

    # åˆ†æè´§æ¶ - è‡ªåŠ¨ä½¿ç”¨ä¼˜åŒ–çš„æç¤ºè¯
    result = analyzer.analyze(image_path=image_path)

    print("=" * 60)
    print("åˆ†æç»“æœ:")
    print("=" * 60)
    print(result)
    print("=" * 60)

    # å¦‚æœéœ€è¦è‡ªå®šä¹‰æé—®ï¼š
    # result = analyzer.analyze(
    #     image_path=image_path,
    #     prompt="è¯·å‘Šè¯‰æˆ‘è¿™ä¸ªè´§æ¶æœ‰å‡ å±‚ï¼Œæ¯å±‚ä¹‹é—´çš„è¿æ¥æ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿ"
    # )


if __name__ == "__main__":
    # å®‰è£…è¯´æ˜
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘        è´§æ¶æ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ - è§†è§‰æ¨¡å‹åˆ†æ                        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ğŸ¯ ä»»åŠ¡ç›®æ ‡: è¯†åˆ«è´§æ¶å±‚æ•°ã€éƒ¨ä»¶å’Œç»„è£…æ–¹å¼

    â­ æ–¹æ¡ˆ 1: æ™ºè°± AI GLM-4Vï¼ˆæ¨èï¼‰
    ----------------------------------------
    âœ… ä¼˜ç‚¹: è¯†åˆ«èƒ½åŠ›å¼ºï¼Œè®¡æ•°å‡†ç¡®ï¼Œä¸­æ–‡æ”¯æŒå¥½
    ğŸ“ æ³¨å†Œ: https://open.bigmodel.cn/
    ğŸ’° è´¹ç”¨: æœ‰å…è´¹é¢åº¦

    â­ æ–¹æ¡ˆ 2: ç¡…åŸºæµåŠ¨ Qwen2-VLï¼ˆå¼€æºæ¨¡å‹ï¼‰
    ----------------------------------------
    âœ… ä¼˜ç‚¹: Qwen2-VL å¯¹è®¡æ•°å’Œç»†èŠ‚è¯†åˆ«å¥½ï¼Œä»·æ ¼ä½
    ğŸ“ æ³¨å†Œ: https://siliconflow.cn/
    ğŸ’° è´¹ç”¨: æä½ä»·æ ¼

    æ–¹æ¡ˆ 3: Ollama æœ¬åœ°è¿è¡Œï¼ˆéœ€ä¸‹è½½ 4GBï¼‰
    -------------------------------------
    âœ… ä¼˜ç‚¹: å®Œå…¨æœ¬åœ°ï¼Œéšç§å®‰å…¨
    âŒ ç¼ºç‚¹: éœ€è¦ä¸‹è½½æ¨¡å‹
    ğŸ“ å®‰è£…: ollama pull llava æˆ– ollama pull qwen2-vl

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ’¡ æ¨è: æ™ºè°± AI æˆ–ç¡…åŸºæµåŠ¨ï¼Œè¯†åˆ«å‡†ç¡®ï¼Œå³åˆ»å¯ç”¨ï¼
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    main()