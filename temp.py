"""
å›¾ç‰‡åˆ†æå™¨ - 

æ”¯æŒçš„æ–¹æ¡ˆï¼š
1. æ™ºè°± AI GLM-4Vï¼ˆæ¨èï¼Œåœ¨çº¿ APIï¼Œè¯†åˆ«èƒ½åŠ›å¼ºï¼‰
2. ç¡…åŸºæµåŠ¨ Qwen2-VLï¼ˆå¼€æºæ¨¡å‹ï¼Œä¾¿å®œï¼Œè®¡æ•°å‡†ç¡®ï¼‰
3. Ollama + LLaVAï¼ˆæœ¬åœ°è¿è¡Œï¼‰
4. Hugging Face Transformersï¼ˆBLIPï¼ŒåŸºç¡€åŠŸèƒ½ï¼‰
"""

import base64
import requests
import json
from pathlib import Path
import os


class ImageAnalyzer:
    """ä½¿ç”¨å¼€æºæ¨¡å‹åˆ†æå›¾ç‰‡å†…å®¹"""

    def __init__(self, method="zhipu", api_key=None):
        """
        åˆå§‹åŒ–å›¾ç‰‡åˆ†æå™¨

        Args:
            method: ä½¿ç”¨çš„æ–¹æ³•ï¼Œå¯é€‰:
                   - "zhipu": æ™ºè°± AI GLM-4Vï¼ˆæ¨èï¼Œè¯†åˆ«èƒ½åŠ›å¼ºï¼‰
                   - "siliconflow": ç¡…åŸºæµåŠ¨ Qwen2-VLï¼ˆå¼€æºï¼Œè®¡æ•°å¥½ï¼‰
                   - "ollama": Ollama æœ¬åœ°
                   - "huggingface": HF Transformers
            api_key: API å¯†é’¥ï¼ˆåœ¨çº¿æ–¹æ¡ˆéœ€è¦ï¼‰
        """
        self.method = method
        self.api_key = api_key or os.getenv(f"{method.upper()}_API_KEY")

    def analyze_with_zhipu(self, image_path, prompt="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"):
        """
        ä½¿ç”¨æ™ºè°± AI GLM-4V æ¨¡å‹åˆ†æå›¾ç‰‡ï¼ˆæ¨èï¼Œè¯†åˆ«èƒ½åŠ›å¼ºï¼‰

        å…è´¹æ³¨å†Œ: https://open.bigmodel.cn/
        æ¯æœˆæœ‰å…è´¹é¢åº¦ï¼Œè§†è§‰ç†è§£èƒ½åŠ›å¼ºï¼Œé€‚åˆè®¡æ•°å’Œç»†èŠ‚è¯†åˆ«

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not self.api_key:
            return """
é”™è¯¯: æœªè®¾ç½® API Key

è·å–æ­¥éª¤ï¼ˆ1åˆ†é’Ÿå®Œæˆï¼‰:
1. è®¿é—® https://open.bigmodel.cn/
2. æ³¨å†Œè´¦å·ï¼ˆæ‰‹æœºå·å³å¯ï¼‰
3. è¿›å…¥"API Keys"é¡µé¢åˆ›å»ºå¯†é’¥
4. æ¯æœˆæœ‰å…è´¹é¢åº¦ï¼Œé€‚åˆè´§æ¶è¯†åˆ«ä»»åŠ¡

ä½¿ç”¨æ–¹æ³•:
analyzer = ImageAnalyzer(method="zhipu", api_key="ä½ çš„å¯†é’¥")
"""

        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')

        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        payload = {
            "model": "glm-4v",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ]
        }

        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except requests.exceptions.HTTPError as e:
            if response.status_code == 401:
                return "é”™è¯¯: API Key æ— æ•ˆï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®"
            return f"HTTP é”™è¯¯: {e}\nå“åº”: {response.text}"
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze_with_siliconflow(self, image_path, prompt="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"):
        """
        ä½¿ç”¨ç¡…åŸºæµåŠ¨ Qwen2-VL æ¨¡å‹åˆ†æå›¾ç‰‡ï¼ˆå¼€æºæ¨¡å‹ï¼Œè®¡æ•°å‡†ç¡®ï¼‰

        æ³¨å†Œ: https://siliconflow.cn/
        ä»·æ ¼æä½ï¼Œä½¿ç”¨ Qwen2-VL å¼€æºæ¨¡å‹ï¼Œå¯¹ä¸­æ–‡å’Œè®¡æ•°æ”¯æŒå¥½

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not self.api_key:
            return """
é”™è¯¯: æœªè®¾ç½® API Key

è·å–æ­¥éª¤:
1. è®¿é—® https://siliconflow.cn/
2. æ³¨å†Œè´¦å·
3. è·å– API Key
4. ä»·æ ¼æä½ï¼Œé€‚åˆæ‰¹é‡å¤„ç†

ä½¿ç”¨æ–¹æ³•:
analyzer = ImageAnalyzer(method="siliconflow", api_key="ä½ çš„å¯†é’¥")
"""

        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')

        url = "https://api.siliconflow.cn/v1/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        payload = {
            "model": "Pro/Qwen/Qwen2-VL-7B-Instruct",  # Qwen2-VL å¯¹è®¡æ•°å’Œç»†èŠ‚è¯†åˆ«å¥½
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            "stream": False
        }

        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze_with_ollama(self, image_path, prompt="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"):
        """
        ä½¿ç”¨ Ollama + LLaVA æ¨¡å‹åˆ†æå›¾ç‰‡

        éœ€è¦å…ˆå®‰è£… Ollama:
        1. ä¸‹è½½: https://ollama.ai/download
        2. è¿è¡Œ: ollama pull llava

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')

        # è°ƒç”¨ Ollama API
        url = "http://localhost:11434/api/generate"
        payload = {
            "model": "llava",
            "prompt": prompt,
            "images": [image_data],
            "stream": False
        }

        try:
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            result = response.json()
            return result.get("response", "")

        except requests.exceptions.ConnectionError:
            return "é”™è¯¯: æ— æ³•è¿æ¥åˆ° Ollamaã€‚è¯·ç¡®ä¿å·²å®‰è£…å¹¶è¿è¡Œ Ollama æœåŠ¡ã€‚\nå®‰è£…æ­¥éª¤:\n1. è®¿é—® https://ollama.ai/download\n2. å®‰è£…åè¿è¡Œ: ollama pull llava"
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze_with_huggingface(self, image_path, prompt=None):
        """
        ä½¿ç”¨ Hugging Face Transformers çš„ BLIP-2 æ¨¡å‹åˆ†æå›¾ç‰‡

        éœ€è¦å®‰è£…: pip install transformers pillow torch

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯ï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆå®Œæ•´æè¿°ï¼‰

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        try:
            from transformers import BlipProcessor, BlipForConditionalGeneration
            from PIL import Image
            import torch

            print("æ­£åœ¨åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")

            # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
            processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
            model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large")

            # è¯»å–å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')

            print("æ­£åœ¨åˆ†æå›¾ç‰‡...")

            if prompt:
                # å¦‚æœæœ‰æç¤ºè¯ï¼Œä½¿ç”¨æ¡ä»¶ç”Ÿæˆï¼ˆVisual Question Answeringï¼‰
                inputs = processor(image, return_tensors="pt")
                # out = model.generate(**inputs, max_length=100, num_beams=5)
                out = model.generate(
                    **inputs,
                    max_length=100,           # å¢åŠ æœ€å¤§é•¿åº¦
                    # min_length=20,            # è®¾ç½®æœ€å°é•¿åº¦ï¼Œç¡®ä¿è¾“å‡ºå®Œæ•´
                    # num_beams=5,              # ä½¿ç”¨æŸæœç´¢ï¼Œæé«˜è´¨é‡
                    length_penalty=1.0,       # é•¿åº¦æƒ©ç½š
                    early_stopping=True,
                    temperature=1.0,
                    do_sample=True
                )
            else:
                # æ— æ¡ä»¶ç”Ÿæˆï¼ˆImage Captioningï¼‰- ç”Ÿæˆå®Œæ•´æè¿°
                inputs = processor(image, return_tensors="pt")
                out = model.generate(
                    **inputs,
                    max_length=100,           # å¢åŠ æœ€å¤§é•¿åº¦
                    # min_length=20,            # è®¾ç½®æœ€å°é•¿åº¦ï¼Œç¡®ä¿è¾“å‡ºå®Œæ•´
                    # num_beams=5,              # ä½¿ç”¨æŸæœç´¢ï¼Œæé«˜è´¨é‡
                    length_penalty=1.0,       # é•¿åº¦æƒ©ç½š
                    early_stopping=True,
                    temperature=1.0,
                    do_sample=True
                )

            description = processor.decode(out[0], skip_special_tokens=True)

            return description

        except ImportError:
            return "é”™è¯¯: ç¼ºå°‘å¿…è¦çš„åº“ã€‚è¯·è¿è¡Œ: pip install transformers pillow torch"
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze_with_qwen_vl(self, image_path, prompt="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"):
        """
        ä½¿ç”¨ Ollama + Qwen2-VL æ¨¡å‹åˆ†æå›¾ç‰‡ï¼ˆä¸­æ–‡æ•ˆæœæ›´å¥½ï¼‰

        éœ€è¦å…ˆè¿è¡Œ: ollama pull qwen2-vl

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        # è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
        with open(image_path, "rb") as image_file:
            image_data = base64.b64encode(image_file.read()).decode('utf-8')

        # è°ƒç”¨ Ollama API
        url = "http://localhost:11434/api/generate"
        payload = {
            "model": "qwen2-vl",
            "prompt": prompt,
            "images": [image_data],
            "stream": False
        }

        try:
            response = requests.post(url, json=payload, timeout=120)
            response.raise_for_status()
            result = response.json()
            return result.get("response", "")

        except requests.exceptions.ConnectionError:
            return "é”™è¯¯: æ— æ³•è¿æ¥åˆ° Ollamaã€‚è¯·è¿è¡Œ: ollama pull qwen2-vl"
        except Exception as e:
            return f"é”™è¯¯: {str(e)}"

    def analyze(self, image_path, prompt=None):
        """
        åˆ†æå›¾ç‰‡å†…å®¹

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå¯é€‰ï¼‰
                   - å¯¹äºè´§æ¶è¯†åˆ«ï¼Œå»ºè®®è¯¦ç»†æè¿°éœ€æ±‚
                   - ä¾‹å¦‚ï¼š"è¯·ä»”ç»†è§‚å¯Ÿè¿™ä¸ªè´§æ¶ï¼Œå‘Šè¯‰æˆ‘ï¼š1. æœ‰å¤šå°‘å±‚ 2. æ¯å±‚çš„ç»“æ„"

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if not Path(image_path).exists():
            return f"é”™è¯¯: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"

                # å¦‚æœæ²¡æœ‰æä¾› promptï¼Œä½¿ç”¨æ›´è¯¦ç»†çš„è´§æ¶è¯†åˆ«æç¤ºè¯ï¼ˆç»“æ„åŒ–ã€åŒ…å«ç¤ºä¾‹ä¸è¯´æ˜ï¼‰
                if prompt is None:
                        prompt = """
ä¸»ä½“å®šä¹‰ (Subject Definition)
è¯·é¦–å…ˆç”¨ä¸€å¥è¯æä¾›ä¸»ä½“çš„æ ¸å¿ƒæè¿°ï¼Œæ ¼å¼ä¸ºï¼š
- [å±‚æ•°/é«˜åº¦] + [æè´¨] + [ä¸»ä½“åç§°]
ç¤ºä¾‹ï¼š"4å±‚é‡å‹é’¢åˆ¶è´§æ¶" æˆ– "2ç±³é«˜è‡ªåŠ¨åŒ–ç«‹ä½“åº“è´§æ¶"

æ•´ä½“é…è‰²ï¼šè¯·æè¿°æ¡†æ¶ä¸æ‰¿è½½é¢çš„ä¸»è‰²æ­é…ï¼Œæ ¼å¼ä¸ºï¼š
- [é¢œè‰²A] (æ¡†æ¶) + [é¢œè‰²B] (æ‰¿è½½é¢)ï¼Œä¾‹å¦‚ï¼š"è“è‰²ç«‹æŸ±é…æ©™è‰²æ¨ªæ¢" æˆ– "å…¨ç°è‰²å·¥ä¸šé£"ã€‚

å‚ç›´æ„ä»¶ (Vertical Components - The Skeleton)
ç«‹æŸ± (Columns/Uprights)ï¼š
- æ•°é‡ï¼šè¯·ç»™å‡ºå¯è§æ•°é‡ï¼ˆå¦‚ï¼š4æ ¹ï¼‰æˆ–ä¼°è®¡èŒƒå›´
- å½¢æ€ï¼šæè¿°æˆªé¢å½¢çŠ¶ï¼ˆä¾‹å¦‚ï¼šè§’é’¢ Angle steel / Cå‹é’¢ C-channel / æ–¹é’¢ squareï¼‰
- ç‰¹å¾ï¼šå­”å‹æˆ–ç»†èŠ‚ï¼ˆå¦‚ï¼šå¸¦è°ƒèŠ‚å­” slotted / å†²å­” punched / æ— å­” solidï¼‰
- é¢œè‰²ï¼šè‹¥å¯è§ï¼Œè¯·è¯´æ˜é¢œè‰²

ä¾§é¢æ”¯æ’‘ (Side Bracing)ï¼š
- å½¢æ€ï¼šå¦‚ Z å­—å½¢(Zig-zag) / X äº¤å‰(Cross-bracing) / æ°´å¹³ç›´æ‹‰(Horizontal)
- ä½ç½®ï¼šè¿æ¥å‰åç«‹æŸ±è¿˜æ˜¯ä¾§é¢

æ°´å¹³æ„ä»¶ (Horizontal Components - The Load)
æ¨ªæ¢ (Beams)ï¼š
- åˆ†å¸ƒï¼šæ¯å±‚å¯è§çš„æ¨ªæ¢æ•°é‡ï¼ˆé€šå¸¸ä¸»è§†å¯è§1æ ¹ï¼Œå®é™…ä¸ºå‰å2æ ¹ï¼‰
- è¿æ¥æ–¹å¼ï¼šæŒ‚æ¥(hooked into) / èºæ “å›ºå®š(bolted to) / å…¶ä»–
- é¢œè‰²ï¼šè‹¥å¯è§è¯´æ˜é¢œè‰²

å±‚æ¿/æ‰¿è½½é¢ (Shelves/Decking)ï¼š
- æ„æˆé€»è¾‘ï¼ˆå•å±‚æ„æˆæ–¹å¼ï¼‰é€‰æ‹©ï¼š
    - é€‰é¡¹ Aï¼šæ•´å—æ¿ (Single continuous panel)
    - é€‰é¡¹ Bï¼šåˆ†å—æ‹¼æ¥ (Composed of 2 adjacent panels)
    - é€‰é¡¹ Cï¼šç½‘æ ¼æ¿ (Wire mesh decking)
- ç»†èŠ‚ç‰¹å¾ï¼šæ˜¯å¦æœ‰æ‹¼æ¥ç¼ï¼ˆå¦‚ï¼šä¸­é—´æœ‰æ˜æ˜¾æ¥ç¼ visible seam in centerï¼‰ã€æ˜¯å¦æœ‰æ”¯æ’‘æ¡ã€å­”æ´ç­‰

é¢å¤–è¦æ±‚ï¼ˆè¾“å‡ºæ ¼å¼ä¸ä¸ç¡®å®šæ€§å¤„ç†ï¼‰:
- è¯·åœ¨å›ç­”ä¸­åˆ†åˆ«ç»™å‡ºâ€œè‡ªç„¶è¯­è¨€æè¿°â€ä¸ä¸€ä¸ªç®€æ´çš„ç»“æ„åŒ– JSON æ®µï¼ˆåŒ…å«ä¸Šé¢å„é¡¹å­—æ®µï¼‰ï¼Œä¾¿äºåç»­å‚æ•°è§£æã€‚
- å¯¹äºä¸ç¡®å®šæˆ–æ— æ³•ä»å›¾ç‰‡ç›´æ¥åˆ¤æ–­çš„é¡¹ï¼Œè¯·ç”¨ "UNKNOWN" æ ‡æ³¨å¹¶ç»™å‡ºä½ åˆ¤æ–­çš„ç½®ä¿¡åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰ä¸ç®€çŸ­ç†ç”±ã€‚
- å¦‚æœèƒ½ä¼°è®¡å°ºå¯¸ï¼ˆå¦‚å±‚é«˜ã€å®½åº¦ã€æ·±åº¦ï¼‰ï¼Œè¯·ç»™å‡ºä¼°è®¡å€¼åŠå•ä½ï¼ˆmm æˆ– mï¼‰å’Œä¼°è®¡ä¾æ®ã€‚

ç¤ºä¾‹è¾“å‡ºç»“æ„ï¼ˆJSON æ¨¡æ¿ï¼‰:
{
    "subject": "4å±‚é‡å‹é’¢åˆ¶è´§æ¶",
    "colors": {"frame": "blue", "decking": "orange"},
    "vertical_components": {"count": 4, "section": "è§’é’¢", "hole_type": "slotted", "color": "blue"},
    "bracing": {"type": "X", "position": "rear"},
    "beams": {"per_level_visible": 1, "actual_per_level": 2, "connection": "hooked", "color": "orange"},
    "decking": {"type": "wire_mesh", "panels": "single", "seam": "none"},
    "estimates": {"bay_width_mm": 2400, "bay_depth_mm": 1000, "level_height_mm": 1800}
}

è¯·åŸºäºå›¾ç‰‡å°½å¯èƒ½å®Œæ•´ã€å‡†ç¡®åœ°å¡«å……ä¸Šè¿°ä¿¡æ¯ã€‚
"""

        print(f"ä½¿ç”¨æ–¹æ³•: {self.method}")
        print(f"åˆ†æå›¾ç‰‡: {image_path}")
        print(f"æç¤ºè¯: {prompt}\n")

        if self.method == "zhipu":
            return self.analyze_with_zhipu(image_path, prompt)
        elif self.method == "siliconflow":
            return self.analyze_with_siliconflow(image_path, prompt)
        elif self.method == "ollama":
            return self.analyze_with_ollama(image_path, prompt)
        elif self.method == "qwen":
            return self.analyze_with_qwen_vl(image_path, prompt)
        elif self.method == "huggingface":
            return self.analyze_with_huggingface(image_path, prompt)
        else:
            return f"ä¸æ”¯æŒçš„æ–¹æ³•: {self.method}"


def main():
    """ä¸»å‡½æ•° - è´§æ¶è¯†åˆ«ç¤ºä¾‹"""

    # é…ç½®ä½ çš„è´§æ¶å›¾ç‰‡è·¯å¾„
    image_path = "./input_img/img_test_03.jpg"  # ä¿®æ”¹ä¸ºä½ çš„å›¾ç‰‡è·¯å¾„

    # ========== æ–¹æ¡ˆ1: æ™ºè°± AI GLM-4Vï¼ˆæ¨èï¼‰==========
    # è¯†åˆ«èƒ½åŠ›å¼ºï¼Œé€‚åˆè®¡æ•°å’Œç»†èŠ‚åˆ†æ
    # æ³¨å†Œ: https://open.bigmodel.cn/
    analyzer = ImageAnalyzer(
        method="zhipu", 
        api_key="c1a1c3a1ee394b4c88a2b138f2d01af6.GOiAiXgVVUsFbI7P"  # æ›¿æ¢ä¸ºä½ çš„å¯†é’¥
    )

    # ========== æ–¹æ¡ˆ2: ç¡…åŸºæµåŠ¨ Qwen2-VLï¼ˆå¼€æºæ¨¡å‹ï¼Œä¾¿å®œï¼‰==========
    # Qwen2-VL å¯¹è®¡æ•°å’Œä¸­æ–‡æ”¯æŒå¥½
    # æ³¨å†Œ: https://siliconflow.cn/
    # analyzer = ImageAnalyzer(
    #     method="siliconflow",
    #     api_key="ä½ çš„APIå¯†é’¥"
    # )

    # ========== æ–¹æ¡ˆ3: æœ¬åœ° Ollamaï¼ˆéœ€ä¸‹è½½ 4GBï¼‰==========
    # analyzer = ImageAnalyzer(method="ollama")

    # åˆ†æè´§æ¶ - è‡ªåŠ¨ä½¿ç”¨ä¼˜åŒ–çš„æç¤ºè¯
    result = analyzer.analyze(image_path=image_path)

    print("=" * 60)
    print("åˆ†æç»“æœ:")
    print("=" * 60)
    print(result)
    print("=" * 60)

    # å¦‚æœéœ€è¦è‡ªå®šä¹‰æé—®ï¼š
    # result = analyzer.analyze(
    #     image_path=image_path,
    #     prompt="è¯·å‘Šè¯‰æˆ‘è¿™ä¸ªè´§æ¶æœ‰å‡ å±‚ï¼Œæ¯å±‚ä¹‹é—´çš„è¿æ¥æ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿ"
    # )


if __name__ == "__main__":
    # å®‰è£…è¯´æ˜
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘        è´§æ¶æ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ - è§†è§‰æ¨¡å‹åˆ†æ                        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ğŸ¯ ä»»åŠ¡ç›®æ ‡: è¯†åˆ«è´§æ¶å±‚æ•°ã€éƒ¨ä»¶å’Œç»„è£…æ–¹å¼

    â­ æ–¹æ¡ˆ 1: æ™ºè°± AI GLM-4Vï¼ˆæ¨èï¼‰
    ----------------------------------------
    âœ… ä¼˜ç‚¹: è¯†åˆ«èƒ½åŠ›å¼ºï¼Œè®¡æ•°å‡†ç¡®ï¼Œä¸­æ–‡æ”¯æŒå¥½
    ğŸ“ æ³¨å†Œ: https://open.bigmodel.cn/
    ğŸ’° è´¹ç”¨: æœ‰å…è´¹é¢åº¦

    â­ æ–¹æ¡ˆ 2: ç¡…åŸºæµåŠ¨ Qwen2-VLï¼ˆå¼€æºæ¨¡å‹ï¼‰
    ----------------------------------------
    âœ… ä¼˜ç‚¹: Qwen2-VL å¯¹è®¡æ•°å’Œç»†èŠ‚è¯†åˆ«å¥½ï¼Œä»·æ ¼ä½
    ğŸ“ æ³¨å†Œ: https://siliconflow.cn/
    ğŸ’° è´¹ç”¨: æä½ä»·æ ¼

    æ–¹æ¡ˆ 3: Ollama æœ¬åœ°è¿è¡Œï¼ˆéœ€ä¸‹è½½ 4GBï¼‰
    -------------------------------------
    âœ… ä¼˜ç‚¹: å®Œå…¨æœ¬åœ°ï¼Œéšç§å®‰å…¨
    âŒ ç¼ºç‚¹: éœ€è¦ä¸‹è½½æ¨¡å‹
    ğŸ“ å®‰è£…: ollama pull llava æˆ– ollama pull qwen2-vl

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ’¡ æ¨è: æ™ºè°± AI æˆ–ç¡…åŸºæµåŠ¨ï¼Œè¯†åˆ«å‡†ç¡®ï¼Œå³åˆ»å¯ç”¨ï¼
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    main()